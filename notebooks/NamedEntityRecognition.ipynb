{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import Counter\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the email modules we'll need\n",
    "import glob\n",
    "import email\n",
    "import mailparser\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "path = '../datawe/raw/Email_Classification/*'\n",
    "email_types = glob.glob(path)\n",
    "appendFilesData = []\n",
    "file_raw_data = [] \n",
    "for folder in email_types:\n",
    "    files = glob.glob(folder+\"/*.txt\")\n",
    "    email_type = folder.split('\\\\')[1]\n",
    "    for name in files:\n",
    "        try:\n",
    "            with open(name) as fp:\n",
    "                raw_data = fp.read()\n",
    "                file_raw_data.append(raw_data)\n",
    "                msg = mailparser.parse_from_string(raw_data)\n",
    "                appendFilesData.append({\n",
    "                    \"to\":msg.to,\n",
    "                    \"from\":msg.from_,\n",
    "                    \"subject\":msg.subject,\n",
    "                    \"date\":msg.date,\n",
    "#                     \"sent\":msg[\"Sent\"],\n",
    "#                     \"importance\":msg[\"Importance\"],\n",
    "                    \"content\":  msg.body,\n",
    "                    \"class_to_exec\":email_type,\n",
    "                })\n",
    "         \n",
    "        except IOError as exc:\n",
    "            print('Exception')\n",
    "\n",
    "            \n",
    "#creating pandas dataframe\n",
    "data = pd.DataFrame(appendFilesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = data[\"content\"][:1]\n",
    "entityData = []\n",
    "for cnt in body:\n",
    "    entityCh = []\n",
    "    entity = nlp(cnt)\n",
    "    for token in entity.ents:\n",
    "        entityData.append({\"text\":token.text, \"label\":token.label_})\n",
    "#     entityData.append(entityCh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityDF = pd.DataFrame(entityData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CARDINAL    2\n",
       "PERSON      2\n",
       "DATE        2\n",
       "FAC         1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityDF[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entityDF[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = nlp('. '.join(np.array(data[\"content\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in text:\n",
    "#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "#           token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entityDtl = []\n",
    "# for token in text.ents:\n",
    "#     if len(token.text.rstrip()) > 0:\n",
    "#         entityDtl.append({\"label\":token.label_, \"text\":token.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# entyDF = pd.DataFrame(entityDtl)\n",
    "# entyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(entyDF[\"text\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "Dear Sir/ Madam,\n",
    "\n",
    " \n",
    "\n",
    "Greetings of the day!\n",
    "\n",
    " \n",
    "\n",
    "As per your request, I am pleased to assist you with the reservation\n",
    "details as follows:\n",
    "\n",
    " \n",
    "\n",
    "*         Reservation #: 75677SB034081\n",
    "\n",
    "*         Guest Name: Saroj Kumar\n",
    "\n",
    "*         Hotel: Taj Dubai\n",
    "\n",
    "*         Dates of Stay: Tue Nov 20 - Sun Nov 25, 2018\n",
    "\n",
    "*         Room: Luxury Burj View Room King Bed\n",
    "\n",
    "*         Rate: Stay a Bit Longer â€“ AED 6500.61\n",
    "\n",
    "*         Inclusions: Breakfast, complimentary shuttle to Dubai mall at\n",
    "fixed timings and Wi-Fi upto 4 devices \n",
    "\n",
    "*         Cancellation: Reservations must be cancelled by 2PM - 1 day\n",
    "prior to arrival to avoid a penalty of 1 night charge plus taxes\n",
    "\n",
    " \n",
    "\n",
    "Please do not hesitate to contact us if we may be of further assistance\n",
    "to you.\n",
    "\n",
    " \n",
    "\n",
    "Warm Regards,\n",
    "\n",
    "Diana Chettiar\n",
    "\n",
    "Taj Reservations Worldwide Team\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # en_core_web_sm = spacy.load('en_core_web_sm')\n",
    "# # en_core_web_md = spacy.load('en_core_web_md')\n",
    "# # en_core_web_lg = spacy.load('en_core_web_lg')\n",
    "# # en_vectors_web_lg = spacy.load('en_vectors_web_lg')\n",
    "\n",
    "\n",
    "\n",
    "# # en_core_web_sm_doc = en_core_web_sm(sentence)\n",
    "# # en_core_web_md_doc = en_core_web_md(sentence)\n",
    "# # en_core_web_lg_doc = en_core_web_lg(sentence)\n",
    "# # en_vectors_web_lg_doc = en_vectors_web_lg(sentence)\n",
    "\n",
    "# doc = nlp(sentence)\n",
    "\n",
    "# entityDtl = []\n",
    "# for token in text.ents:\n",
    "#     if len(token.text.rstrip()) > 0:\n",
    "#         entityDtl.append({\"label\":token.label_, \"text\":token.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(entityDtl)\n",
    "\n",
    "entities = {\"GPE\":\"Location\",\n",
    " \"ORG\":\"organization\",\n",
    " \"PERSON\":\"Name\",\n",
    " \"DATE\":\"Date\",\n",
    " \"TIME\" : \"Time\",\n",
    " \"CARDINAL\": \"CARDINAL\"\n",
    "}\n",
    "stemmer = SnowballStemmer(\"english\").stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp(sentence)\n",
    "entityDtl = []\n",
    "for token in text.ents:\n",
    "    wrd = token.text.strip()\n",
    "    label_ =  token.label_\n",
    "#     if len(wrd) > 0:\n",
    "#         entityDtl.append({\"label\":token.label_, \"text\":token.text.strip()})\n",
    "\n",
    "    if len(wrd) > 0 and label_ in entities and ((label_ == \"PERSON\" and wrd.replace(' ','').isalpha() and stemmer(wrd) == wrd.lower()) or label_ != \"PERSON\"):\n",
    "        entityDtl.append({\"label\":token.label_, \"text\":token.text.strip()})\n",
    "\n",
    "entityDtlDF = pd.DataFrame(entityDtl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n\\n', 5), ('Sir/ Madam', 1), ('\\n\\n \\n\\n', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names = entityDtlDF[entityDtlDF[\"label\"] == \"PERSON\"][\"text\"]\n",
    "\n",
    "# # names.\n",
    "\n",
    "# stemmer = SnowballStemmer(\"english\").stem\n",
    "# stem_free = [stemmer(stem) for stem in names if stem]\n",
    "# stem_free\n",
    "items = [x.text for x in text.ents]\n",
    "Counter(items).most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>75677SB034081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>Guest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>Saroj Kumar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>Taj Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATE</td>\n",
       "      <td>Tue Nov 20 - Sun Nov 25,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATE</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>6500.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPE</td>\n",
       "      <td>Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DATE</td>\n",
       "      <td>2PM - 1 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TIME</td>\n",
       "      <td>1 night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                      text\n",
       "0  CARDINAL             75677SB034081\n",
       "1    PERSON                     Guest\n",
       "2    PERSON               Saroj Kumar\n",
       "3    PERSON                 Taj Dubai\n",
       "4      DATE  Tue Nov 20 - Sun Nov 25,\n",
       "5      DATE                      2018\n",
       "6  CARDINAL                   6500.61\n",
       "7       GPE                     Dubai\n",
       "8      DATE               2PM - 1 day\n",
       "9      TIME                   1 night"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityDtlDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((label_ == \"PERSON\" and wrd.isalpha() and stemmer(wrd) == wrd) or label_ != \"PERSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer(wrd) == wrd.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diana chettiar'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer(wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.53906965\n",
      "dog banana 0.28761008\n",
      "cat dog 0.53906965\n",
      "cat cat 1.0\n",
      "cat banana 0.4875216\n",
      "banana dog 0.28761008\n",
      "banana cat 0.4875216\n",
      "banana banana 1.0\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load('en_core_web_md')  # make sure to use larger model!\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class str in module builtins:\n",
      "\n",
      "class str(object)\n",
      " |  str(object='') -> str\n",
      " |  str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
      " |  \n",
      " |  Create a new string object from the given object. If encoding or\n",
      " |  errors is specified, then the object must expose a data buffer\n",
      " |  that will be decoded using the given encoding and error handler.\n",
      " |  Otherwise, returns the result of object.__str__() (if defined)\n",
      " |  or repr(object).\n",
      " |  encoding defaults to sys.getdefaultencoding().\n",
      " |  errors defaults to 'strict'.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(...)\n",
      " |      S.__format__(format_spec) -> str\n",
      " |      \n",
      " |      Return a formatted version of S as described by format_spec.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __getnewargs__(...)\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      S.__sizeof__() -> size of S in memory, in bytes\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  capitalize(...)\n",
      " |      S.capitalize() -> str\n",
      " |      \n",
      " |      Return a capitalized version of S, i.e. make the first character\n",
      " |      have upper case and the rest lower case.\n",
      " |  \n",
      " |  casefold(...)\n",
      " |      S.casefold() -> str\n",
      " |      \n",
      " |      Return a version of S suitable for caseless comparisons.\n",
      " |  \n",
      " |  center(...)\n",
      " |      S.center(width[, fillchar]) -> str\n",
      " |      \n",
      " |      Return S centered in a string of length width. Padding is\n",
      " |      done using the specified fill character (default is a space)\n",
      " |  \n",
      " |  count(...)\n",
      " |      S.count(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the number of non-overlapping occurrences of substring sub in\n",
      " |      string S[start:end].  Optional arguments start and end are\n",
      " |      interpreted as in slice notation.\n",
      " |  \n",
      " |  encode(...)\n",
      " |      S.encode(encoding='utf-8', errors='strict') -> bytes\n",
      " |      \n",
      " |      Encode S using the codec registered for encoding. Default encoding\n",
      " |      is 'utf-8'. errors may be given to set a different error\n",
      " |      handling scheme. Default is 'strict' meaning that encoding errors raise\n",
      " |      a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n",
      " |      'xmlcharrefreplace' as well as any other name registered with\n",
      " |      codecs.register_error that can handle UnicodeEncodeErrors.\n",
      " |  \n",
      " |  endswith(...)\n",
      " |      S.endswith(suffix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S ends with the specified suffix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      suffix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  expandtabs(...)\n",
      " |      S.expandtabs(tabsize=8) -> str\n",
      " |      \n",
      " |      Return a copy of S where all tab characters are expanded using spaces.\n",
      " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      " |  \n",
      " |  find(...)\n",
      " |      S.find(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  format(...)\n",
      " |      S.format(*args, **kwargs) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  format_map(...)\n",
      " |      S.format_map(mapping) -> str\n",
      " |      \n",
      " |      Return a formatted version of S, using substitutions from mapping.\n",
      " |      The substitutions are identified by braces ('{' and '}').\n",
      " |  \n",
      " |  index(...)\n",
      " |      S.index(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the lowest index in S where substring sub is found, \n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  isalnum(...)\n",
      " |      S.isalnum() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are alphanumeric\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  isalpha(...)\n",
      " |      S.isalpha() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are alphabetic\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  isdecimal(...)\n",
      " |      S.isdecimal() -> bool\n",
      " |      \n",
      " |      Return True if there are only decimal characters in S,\n",
      " |      False otherwise.\n",
      " |  \n",
      " |  isdigit(...)\n",
      " |      S.isdigit() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are digits\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  isidentifier(...)\n",
      " |      S.isidentifier() -> bool\n",
      " |      \n",
      " |      Return True if S is a valid identifier according\n",
      " |      to the language definition.\n",
      " |      \n",
      " |      Use keyword.iskeyword() to test for reserved identifiers\n",
      " |      such as \"def\" and \"class\".\n",
      " |  \n",
      " |  islower(...)\n",
      " |      S.islower() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in S are lowercase and there is\n",
      " |      at least one cased character in S, False otherwise.\n",
      " |  \n",
      " |  isnumeric(...)\n",
      " |      S.isnumeric() -> bool\n",
      " |      \n",
      " |      Return True if there are only numeric characters in S,\n",
      " |      False otherwise.\n",
      " |  \n",
      " |  isprintable(...)\n",
      " |      S.isprintable() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are considered\n",
      " |      printable in repr() or S is empty, False otherwise.\n",
      " |  \n",
      " |  isspace(...)\n",
      " |      S.isspace() -> bool\n",
      " |      \n",
      " |      Return True if all characters in S are whitespace\n",
      " |      and there is at least one character in S, False otherwise.\n",
      " |  \n",
      " |  istitle(...)\n",
      " |      S.istitle() -> bool\n",
      " |      \n",
      " |      Return True if S is a titlecased string and there is at least one\n",
      " |      character in S, i.e. upper- and titlecase characters may only\n",
      " |      follow uncased characters and lowercase characters only cased ones.\n",
      " |      Return False otherwise.\n",
      " |  \n",
      " |  isupper(...)\n",
      " |      S.isupper() -> bool\n",
      " |      \n",
      " |      Return True if all cased characters in S are uppercase and there is\n",
      " |      at least one cased character in S, False otherwise.\n",
      " |  \n",
      " |  join(...)\n",
      " |      S.join(iterable) -> str\n",
      " |      \n",
      " |      Return a string which is the concatenation of the strings in the\n",
      " |      iterable.  The separator between elements is S.\n",
      " |  \n",
      " |  ljust(...)\n",
      " |      S.ljust(width[, fillchar]) -> str\n",
      " |      \n",
      " |      Return S left-justified in a Unicode string of length width. Padding is\n",
      " |      done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  lower(...)\n",
      " |      S.lower() -> str\n",
      " |      \n",
      " |      Return a copy of the string S converted to lowercase.\n",
      " |  \n",
      " |  lstrip(...)\n",
      " |      S.lstrip([chars]) -> str\n",
      " |      \n",
      " |      Return a copy of the string S with leading whitespace removed.\n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  partition(...)\n",
      " |      S.partition(sep) -> (head, sep, tail)\n",
      " |      \n",
      " |      Search for the separator sep in S, and return the part before it,\n",
      " |      the separator itself, and the part after it.  If the separator is not\n",
      " |      found, return S and two empty strings.\n",
      " |  \n",
      " |  replace(...)\n",
      " |      S.replace(old, new[, count]) -> str\n",
      " |      \n",
      " |      Return a copy of S with all occurrences of substring\n",
      " |      old replaced by new.  If the optional argument count is\n",
      " |      given, only the first count occurrences are replaced.\n",
      " |  \n",
      " |  rfind(...)\n",
      " |      S.rfind(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Return -1 on failure.\n",
      " |  \n",
      " |  rindex(...)\n",
      " |      S.rindex(sub[, start[, end]]) -> int\n",
      " |      \n",
      " |      Return the highest index in S where substring sub is found,\n",
      " |      such that sub is contained within S[start:end].  Optional\n",
      " |      arguments start and end are interpreted as in slice notation.\n",
      " |      \n",
      " |      Raises ValueError when the substring is not found.\n",
      " |  \n",
      " |  rjust(...)\n",
      " |      S.rjust(width[, fillchar]) -> str\n",
      " |      \n",
      " |      Return S right-justified in a string of length width. Padding is\n",
      " |      done using the specified fill character (default is a space).\n",
      " |  \n",
      " |  rpartition(...)\n",
      " |      S.rpartition(sep) -> (head, sep, tail)\n",
      " |      \n",
      " |      Search for the separator sep in S, starting at the end of S, and return\n",
      " |      the part before it, the separator itself, and the part after it.  If the\n",
      " |      separator is not found, return two empty strings and S.\n",
      " |  \n",
      " |  rsplit(...)\n",
      " |      S.rsplit(sep=None, maxsplit=-1) -> list of strings\n",
      " |      \n",
      " |      Return a list of the words in S, using sep as the\n",
      " |      delimiter string, starting at the end of the string and\n",
      " |      working to the front.  If maxsplit is given, at most maxsplit\n",
      " |      splits are done. If sep is not specified, any whitespace string\n",
      " |      is a separator.\n",
      " |  \n",
      " |  rstrip(...)\n",
      " |      S.rstrip([chars]) -> str\n",
      " |      \n",
      " |      Return a copy of the string S with trailing whitespace removed.\n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  split(...)\n",
      " |      S.split(sep=None, maxsplit=-1) -> list of strings\n",
      " |      \n",
      " |      Return a list of the words in S, using sep as the\n",
      " |      delimiter string.  If maxsplit is given, at most maxsplit\n",
      " |      splits are done. If sep is not specified or is None, any\n",
      " |      whitespace string is a separator and empty strings are\n",
      " |      removed from the result.\n",
      " |  \n",
      " |  splitlines(...)\n",
      " |      S.splitlines([keepends]) -> list of strings\n",
      " |      \n",
      " |      Return a list of the lines in S, breaking at line boundaries.\n",
      " |      Line breaks are not included in the resulting list unless keepends\n",
      " |      is given and true.\n",
      " |  \n",
      " |  startswith(...)\n",
      " |      S.startswith(prefix[, start[, end]]) -> bool\n",
      " |      \n",
      " |      Return True if S starts with the specified prefix, False otherwise.\n",
      " |      With optional start, test S beginning at that position.\n",
      " |      With optional end, stop comparing S at that position.\n",
      " |      prefix can also be a tuple of strings to try.\n",
      " |  \n",
      " |  strip(...)\n",
      " |      S.strip([chars]) -> str\n",
      " |      \n",
      " |      Return a copy of the string S with leading and trailing\n",
      " |      whitespace removed.\n",
      " |      If chars is given and not None, remove characters in chars instead.\n",
      " |  \n",
      " |  swapcase(...)\n",
      " |      S.swapcase() -> str\n",
      " |      \n",
      " |      Return a copy of S with uppercase characters converted to lowercase\n",
      " |      and vice versa.\n",
      " |  \n",
      " |  title(...)\n",
      " |      S.title() -> str\n",
      " |      \n",
      " |      Return a titlecased version of S, i.e. words start with title case\n",
      " |      characters, all remaining cased characters have lower case.\n",
      " |  \n",
      " |  translate(...)\n",
      " |      S.translate(table) -> str\n",
      " |      \n",
      " |      Return a copy of the string S in which each character has been mapped\n",
      " |      through the given translation table. The table must implement\n",
      " |      lookup/indexing via __getitem__, for instance a dictionary or list,\n",
      " |      mapping Unicode ordinals to Unicode ordinals, strings, or None. If\n",
      " |      this operation raises LookupError, the character is left untouched.\n",
      " |      Characters mapped to None are deleted.\n",
      " |  \n",
      " |  upper(...)\n",
      " |      S.upper() -> str\n",
      " |      \n",
      " |      Return a copy of S converted to uppercase.\n",
      " |  \n",
      " |  zfill(...)\n",
      " |      S.zfill(width) -> str\n",
      " |      \n",
      " |      Pad a numeric string S with zeros on the left, to fill a field\n",
      " |      of the specified width. The string S is never truncated.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  maketrans(x, y=None, z=None, /)\n",
      " |      Return a translation table usable for str.translate().\n",
      " |      \n",
      " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      " |      Character keys will be then converted to ordinals.\n",
      " |      If there are two arguments, they must be strings of equal length, and\n",
      " |      in the resulting dictionary, each character in x will be mapped to the\n",
      " |      character at the same position in y. If there is a third argument, it\n",
      " |      must be a string, whose characters will be mapped to None in the result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
